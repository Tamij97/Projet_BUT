{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import et test GPT2 Groupe Dracolia\n",
        "\n",
        "Membres:\n",
        "- Bastien HOTTELET\n",
        "- Pascal ZHAN\n",
        "- Fatih FIDAN\n",
        "- Lilian SOARES\n",
        "- Tamij SARAVANAN\n",
        "- Kévin Postic\n",
        "- Evan PARIS\n",
        "\n",
        "Date : 17/11/2023\n",
        "\n",
        "Description : Importation du modèle pré-entrainé GPT-2 de Keras NLP et réalisation de test sur le modèle afin de comprendre le fonction de GPT-2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CwXWRLs11OqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation Keras NLP, choix de backend de Keras et importation des librairies\n",
        "\n",
        "Avant de procéder à l'importation du modèle, il est nécessaire d'installer Keras NLP"
      ],
      "metadata": {
        "id": "vJMNw2Q734aU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/keras-team/keras-nlp.git -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY60Pzoh332p",
        "outputId": "d88bb0db-6704-4308-9abe-56138ea9de4a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for keras-nlp (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Après avoir réalisé quelques tests, nous avons remarqué que la version **2.15.0** de tensorflow n'arrive pas à détecter le GPU, nous avons décidé de désinstaller cette version et installer la version **2.14.0** puisque celle-ci fonctionne correctement.\n",
        "\n",
        "Par ailleurs, il est nécessaire de redémarrer la session colab pour appliquer les modifications"
      ],
      "metadata": {
        "id": "RtKqYDj28u5s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3QMW-vlv1GQl",
        "outputId": "8a070bf6-0e61-4612-84ed-f35b7475fd59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n",
            "Found existing installation: tensorflow 2.15.0\n",
            "Uninstalling tensorflow-2.15.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.15.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled tensorflow-2.15.0\n",
            "Collecting tensorflow==2.14.0\n",
            "  Downloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.59.2)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow==2.14.0)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow==2.14.0)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.15,>=2.14.0 (from tensorflow==2.14.0)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.14.0) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.1\n",
            "    Uninstalling tensorboard-2.15.1:\n",
            "      Successfully uninstalled tensorboard-2.15.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.14.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.14.0 tensorboard-2.14.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "if tf.__version__ == \"2.15.0\":\n",
        "  !pip uninstall tensorflow\n",
        "  !pip install tensorflow==2.14.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans le cadre de la SAE, nous utilisons le **Keras Core** en le spécificant le lancement sur tensorflow. En effet, il est possible de lancer le **Keras Core** avec d'autres workflows que celui de tensorflow, comme torch et jax"
      ],
      "metadata": {
        "id": "8b3vM7DT9IhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import package\n",
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "import keras_core as keras\n",
        "import time"
      ],
      "metadata": {
        "id": "mkVh63aK3lyU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Introduction à KerasNLP\n",
        "La construction de grands modèles de langage est complexe et coûteuse à partir de zéro. Heureusement, il existe des modèles de langage pré-entraînés disponibles pour une utilisation immédiate. KerasNLP propose un grand nombre de points de contrôle pré-entraînés qui vous permettent d'expérimenter avec des modèles de pointe sans avoir à les entraîner vous-même.\n",
        "\n",
        "KerasNLP est une bibliothèque de traitement du langage naturel qui prend en charge les utilisateurs tout au long de leur cycle de développement. KerasNLP propose à la fois des modèles pré-entraînés et des blocs de construction modulaires, ce qui permet aux développeurs de réutiliser facilement des modèles pré-entraînés ou de créer leurs propres modèles de langage.\n",
        "\n",
        "En résumé, pour les modèles génératifs de langage, KerasNLP propose :\n",
        "\n",
        "Des modèles pré-entraînés avec la méthode generate(), par exemple, keras_nlp.models.GPT2CausalLM et keras_nlp.models.OPTCausalLM.\n",
        "Une classe Sampler qui met en œuvre des algorithmes de génération tels que Top-K, Beam et la recherche contrastive. Ces échantillonneurs peuvent être utilisés pour générer du texte avec des modèles personnalisés."
      ],
      "metadata": {
        "id": "EeOBnOfsCFig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GPT2-base"
      ],
      "metadata": {
        "id": "a2Kh_S0Wf2IE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import GPT2-base"
      ],
      "metadata": {
        "id": "1Q5_-beWgEOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
        "    \"gpt2_base_en\",\n",
        ")\n",
        "gpt2_base = keras_nlp.models.GPT2CausalLM.from_preset(\n",
        "    \"gpt2_base_en\", preprocessor=preprocessor\n",
        ")"
      ],
      "metadata": {
        "id": "H2aMzmqx-oKK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_base.summary() #124,439,808 de paramètres"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "lUXtDkFEfg5i",
        "outputId": "6ceb7021-e747-465c-de67-debaab9ff964"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mPreprocessor: \"gpt2_causal_lm_preprocessor_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gpt2_causal_lm_preprocessor_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gpt2_tokenizer_1 (\u001b[38;5;33mGPT2Tokenizer\u001b[0m)                   │                                              \u001b[38;5;34m50,257\u001b[0m │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gpt2_tokenizer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GPT2Tokenizer</span>)                   │                                              <span style=\"color: #00af00; text-decoration-color: #00af00\">50,257</span> │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gpt2_causal_lm_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt2_causal_lm_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to                  \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │           \u001b[38;5;34m0\u001b[0m │ -                              │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │           \u001b[38;5;34m0\u001b[0m │ -                              │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ gpt2_backbone_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)         │ \u001b[38;5;34m124,439,808\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
              "│ (\u001b[38;5;33mGPT2Backbone\u001b[0m)                │                           │             │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50257\u001b[0m)       │  \u001b[38;5;34m38,597,376\u001b[0m │ gpt2_backbone_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │             │                                │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────┴────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">     Param # </span>┃<span style=\"font-weight: bold\"> Connected to                   </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                              │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                              │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ gpt2_backbone_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">124,439,808</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GPT2Backbone</span>)                │                           │             │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">38,597,376</span> │ gpt2_backbone_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │             │                                │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────┴────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m124,439,808\u001b[0m (474.70 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,439,808</span> (474.70 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m124,439,808\u001b[0m (474.70 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,439,808</span> (474.70 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST GTP-2 base\n",
        "\n",
        "Une fois que nous avons pu charger le model pré-entrainé, nous pouvons réalisé des tests en lui demandant de générer la suite d'un texte.\n",
        "\n",
        "Par ailleurs le modèle est basé en anglais, il faut donc réaliser nos tests en anglais."
      ],
      "metadata": {
        "id": "64TItT_OCgoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "output = gpt2_base.generate(\"French people are\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output)\n",
        "\n",
        "end = time.time()\n",
        "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG2m2jtwBh5r",
        "outputId": "a8e2be59-2cd6-4751-81a3-d1ae1f028e2b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPT-2 output:\n",
            "French people are not allowed to vote in France, but they do vote, according to the government of President François Hollande.\n",
            "\n",
            "France is not a member of the European Economic Community (EEA), but its membership was established by the French in 1975.\n",
            "\n",
            "France has a history of voting in the European Union (EU), the European Parliament (EPC), the European Commission (EC), and the European Parliament of Germany (EPFL) as well as the European Central Bank. However, the country's current membership is based on its relationship with the E.U. and the European Economic Community (EEA), which have been in conflict for decades. The European Commission, which is responsible for the E.U., is currently under a new government in Brussels.\n",
            "\n",
            "In an interview, Hollande said the country's participation in the E.E.C. was \"a positive development\" in its relations with the E.U.\n",
            "\n",
            "\"We have been able to develop relations\n",
            "TOTAL TIME ELAPSED: 14.64s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT-2 output:\n",
        "\n",
        "French people are not allowed to vote in France, but they do vote, according to the government of President François Hollande.\n",
        "\n",
        "France is not a member of the European Economic Community (EEA), but its membership was established by the French in 1975.\n",
        "\n",
        "France has a history of voting in the European Union (EU), the European Parliament (EPC), the European Commission (EC), and the European Parliament of Germany (EPFL) as well as the European Central Bank. However, the country's current membership is based on its relationship with the E.U. and the European Economic Community (EEA), which have been in conflict for decades. The European Commission, which is responsible for the E.U., is currently under a new government in Brussels.\n",
        "\n",
        "In an interview, Hollande said the country's participation in the E.E.C. was \"a positive development\" in its relations with the E.U.\n",
        "\n",
        "\"We have been able to develop relations\n",
        "\n",
        "TOTAL TIME ELAPSED: 14.64s"
      ],
      "metadata": {
        "id": "v1FNzVU2F4RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "output = gpt2_base.generate(\"French people are\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output)\n",
        "\n",
        "end = time.time()\n",
        "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOMRsDhMEDHi",
        "outputId": "79cd779c-0687-4bc9-9535-a49cd9c7a985"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPT-2 output:\n",
            "French people are increasingly concerned over the safety of their food, and are increasingly worried about their health.\n",
            "\n",
            "A recent study by the World Bank and other organizations has found that the risk of heart and respiratory problems in France is increasing, particularly in areas with high levels of obesity.\n",
            "\n",
            "According to the report, France is the second most obese nation in the world, behind only the United States.\n",
            "\n",
            "\"The number of people in France with heart problems and the incidence of type 2 diabetes have increased by nearly 50 percent since 2000, while the rate of obesity among French women has increased by almost 20 percent,\" said the report.\n",
            "\n",
            "The report was published in the European journal Health Policy. The report found that \"the number of people in France who are overweight or obese has increased by about 10 percent since 2000.\"\n",
            "\n",
            "The report also said that \"the health care system in France is becoming increasingly expensive.\"\n",
            "\n",
            "The French government has already started a program to provide free food and\n",
            "TOTAL TIME ELAPSED: 14.36s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT-2 output:\n",
        "\n",
        "French people are increasingly concerned over the safety of their food, and are increasingly worried about their health.\n",
        "\n",
        "A recent study by the World Bank and other organizations has found that the risk of heart and respiratory problems in France is increasing, particularly in areas with high levels of obesity.\n",
        "\n",
        "According to the report, France is the second most obese nation in the world, behind only the United States.\n",
        "\n",
        "\"The number of people in France with heart problems and the incidence of type 2 diabetes have increased by nearly 50 percent since 2000, while the rate of obesity among French women has increased by almost 20 percent,\" said the report.\n",
        "\n",
        "The report was published in the European journal Health Policy. The report found that \"the number of people in France who are overweight or obese has increased by about 10 percent since 2000.\"\n",
        "\n",
        "The report also said that \"the health care system in France is becoming increasingly expensive.\"\n",
        "\n",
        "The French government has already started a program to provide free food and\n",
        "\n",
        "TOTAL TIME ELAPSED: 14.36s"
      ],
      "metadata": {
        "id": "cJmUF0BIHTzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Autres résultats obtenus"
      ],
      "metadata": {
        "id": "5cy2IeIIduEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT-2 output:\n",
        "\n",
        "French people are  tired of their politicians, and they're not going to take it anymore.\n",
        "The French have a long history of voting for the lesser of two evils in order to avoid the worse of the two.  This is why the French were able to get rid of the monarchy, and why they were able to get rid of the aristocracy.  They were able to do so because they were willing to sacrifice their liberties in the process, and they were willing to sacrifice their freedoms in order to avoid the worst of the two.  They are not going to do that anymore, and they are not going to do it by voting for a lesser of two evils.    They will do it by voting for the greatest of two evils.  They're going to vote for the lesser of two evils.\n",
        "And this is where the French people are going to vote in this election:\n",
        "They are going to vote for Marine Le Pen.\n",
        "\n",
        "TOTAL TIME ELAPSED: 52.85s"
      ],
      "metadata": {
        "id": "2D5vQlRTd16d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output:\n",
        "\n",
        "French people are always trying to get me to do the \"right\" thing when it comes to the toilet seat.  \n",
        "\n",
        "so i was sitting on my toilet seat with my back against the wall, and my legs were on the edge of the seat and my backside was on top of it.                                                                                             \n",
        "\n",
        "Total Time Elapsed: 4.17s\n",
        "\n",
        "<hr>\n",
        "\n",
        "Output:\n",
        "\n",
        "French people are so fucking lazy. fuck.\n",
        "                    \n",
        "Total Time Elapsed: 3.36s"
      ],
      "metadata": {
        "id": "vCmMhl0neCYF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT-2 output:\n",
        "\n",
        "What is the capital city of country France ?\n",
        "\n",
        "The capital of France is located in the French province of Brittany and is situated in the southern part of Europe. It is a small country in that it is not as big as most other countries in Europe, but the country of its capital is not as large as other countries. The capital city is located in the city of Marseilles, which is in the city of Marseille. It is the largest city in France, with a population of over 2 million people. It is a small country and its population is small. It has a high quality of life and has a great number of restaurants. It has a good number of hospitals and is the only city in the world with a population of more than 2 million.\n",
        "\n",
        "What is the city of Marseille?\n",
        "\n",
        "The city of Marseille is located in the city of Marseille, which is located in the city of Marseille in the south of France, in the city of\n",
        "\n",
        "TOTAL TIME ELAPSED: 15.68s"
      ],
      "metadata": {
        "id": "F-RBvXqFhsIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GTP2-large\n",
        "\n",
        "Suite aux tests avec gpt2_base, nous apercevons que celui-ci n'est pas assez puissant et donne des résultats un peu douteux.\n",
        "\n",
        "Nous avons passez des tests sur gpt2 qui possède beaucoup plus de paramètres."
      ],
      "metadata": {
        "id": "lfvJbeuUdZJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import GPT2-large"
      ],
      "metadata": {
        "id": "q9fQwSn-f-j9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor_large = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
        "    \"gpt2_large_en\",\n",
        ")\n",
        "gpt2_large = keras_nlp.models.GPT2CausalLM.from_preset(\n",
        "    \"gpt2_large_en\", preprocessor=preprocessor_large\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50sAtnAgF7jU",
        "outputId": "54587207-b7ea-494e-8304-0f9f263a4bef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_large_en/v1/vocab.json\n",
            "\u001b[1m1042301/1042301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step       \n",
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_large_en/v1/merges.txt\n",
            "\u001b[1m456318/456318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step       \n",
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_large_en/v1/model.h5\n",
            "\u001b[1m3096768960/3096768960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_large.summary() #774,030,080 de paramètres"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "bu5YILg2fkDk",
        "outputId": "98c7f18e-11d2-4fbd-8da2-72e4216d6479"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mPreprocessor: \"gpt2_causal_lm_preprocessor_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gpt2_causal_lm_preprocessor_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gpt2_tokenizer_2 (\u001b[38;5;33mGPT2Tokenizer\u001b[0m)                   │                                              \u001b[38;5;34m50,257\u001b[0m │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gpt2_tokenizer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GPT2Tokenizer</span>)                   │                                              <span style=\"color: #00af00; text-decoration-color: #00af00\">50,257</span> │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gpt2_causal_lm_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt2_causal_lm_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to                  \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │           \u001b[38;5;34m0\u001b[0m │ -                              │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │           \u001b[38;5;34m0\u001b[0m │ -                              │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ gpt2_backbone_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)        │ \u001b[38;5;34m774,030,080\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
              "│ (\u001b[38;5;33mGPT2Backbone\u001b[0m)                │                           │             │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50257\u001b[0m)       │  \u001b[38;5;34m64,328,960\u001b[0m │ gpt2_backbone_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │             │                                │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────┴────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">     Param # </span>┃<span style=\"font-weight: bold\"> Connected to                   </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                              │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                              │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ gpt2_backbone_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">774,030,080</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GPT2Backbone</span>)                │                           │             │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">64,328,960</span> │ gpt2_backbone_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │             │                                │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────┴────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m774,030,080\u001b[0m (2.88 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">774,030,080</span> (2.88 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m774,030,080\u001b[0m (2.88 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">774,030,080</span> (2.88 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST GPT2-large"
      ],
      "metadata": {
        "id": "w7QtCJc5gN6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "output = gpt2_large.generate(\"French people are\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output)\n",
        "\n",
        "end = time.time()\n",
        "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VowCBegPflni",
        "outputId": "c962351c-d38e-4ca9-9142-6429af3875e1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPT-2 output:\n",
            "French people are not happy about the government's decision to allow gay marriage and are demanding the government take action on the issue.\n",
            "\n",
            "A recent survey of 1,000 French people conducted by the French polling company Ifop found that a whopping 70.7 percent of those surveyed were opposed to same-sex marriage.\n",
            "\n",
            "This means the country is now the most homophobic nation on the planet.\n",
            "\n",
            "\"The survey shows that French people are not happy about the government's decision to allow gay marriage, and that they want the government to intervene,\" the BBC quoted French President Francois Hollande as saying. \"I think that the people of France want the government to take a strong position on this issue.\"\n",
            "\n",
            "Hollande has been under fire for his decision to allow same-sex marriage. His popularity has plummeted since he made his announcement.\n",
            "\n",
            "The BBC reports that Hollande's approval rating has fallen to just 34 percent, and that he is the most unpopular French president in modern history.\n",
            "TOTAL TIME ELAPSED: 47.22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT-2 output:\n",
        "\n",
        "French people are not happy about the government's decision to allow gay marriage and are demanding the government take action on the issue.\n",
        "\n",
        "A recent survey of 1,000 French people conducted by the French polling company Ifop found that a whopping 70.7 percent of those surveyed were opposed to same-sex marriage.\n",
        "\n",
        "This means the country is now the most homophobic nation on the planet.\n",
        "\n",
        "\"The survey shows that French people are not happy about the government's decision to allow gay marriage, and that they want the government to intervene,\" the BBC quoted French President Francois Hollande as saying. \"I think that the people of France want the government to take a strong position on this issue.\"\n",
        "\n",
        "Hollande has been under fire for his decision to allow same-sex marriage. His popularity has plummeted since he made his announcement.\n",
        "\n",
        "The BBC reports that Hollande's approval rating has fallen to just 34 percent, and that he is the most unpopular French president in modern history.\n",
        "\n",
        "TOTAL TIME ELAPSED: 47.22s"
      ],
      "metadata": {
        "id": "654ypOaLgdMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "output = gpt2_large.generate(\"French people are\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output)\n",
        "\n",
        "end = time.time()\n",
        "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg0xyC7lgZwV",
        "outputId": "3453b442-548c-4532-fea4-f7edb51c33ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPT-2 output:\n",
            "French people are the world's most generous people, according to a study that reveals how the country has the highest per capita generosity in the world.\n",
            "\n",
            "In the study by the charity Oxfam, France was ranked the world's \"best country\" for generosity, ahead of Norway, Switzerland, Finland and the United States.\n",
            "\n",
            "Oxfam found that the average French person donated $1,500 in 2013. This was the second highest per person in the world. The UK was second, with a donation average of $1,200.\n",
            "\n",
            "The charity also found that the average French family gave $1,800 in donations.\n",
            "\n",
            "France has been ranked number one on the Oxfam index since 2008, with the UK in second place, and the US in third.\n",
            "\n",
            "The report also found that France has the highest per capita generosity of any country. In 2013, per person, the UK was the third most generous country in the world, after Switzerland and Denmark.\n",
            "TOTAL TIME ELAPSED: 44.89s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT-2 output:\n",
        "\n",
        "French people are the world's most generous people, according to a study that reveals how the country has the highest per capita generosity in the world.\n",
        "\n",
        "In the study by the charity Oxfam, France was ranked the world's \"best country\" for generosity, ahead of Norway, Switzerland, Finland and the United States.\n",
        "\n",
        "Oxfam found that the average French person donated \\$1,500 in 2013. This was the second highest per person in the world. The UK was second, with a donation average of $1,200.\n",
        "\n",
        "The charity also found that the average French family gave $1,800 in donations.\n",
        "\n",
        "France has been ranked number one on the Oxfam index since 2008, with the UK in second place, and the US in third.\n",
        "\n",
        "The report also found that France has the highest per capita generosity of any country. In 2013, per person, the UK was the third most generous country in the world, after Switzerland and Denmark.\n",
        "\n",
        "TOTAL TIME ELAPSED: 44.89s"
      ],
      "metadata": {
        "id": "hxJD_gnjgyC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autres résultats obtenus"
      ],
      "metadata": {
        "id": "Yr0N3E_7hRqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT-2 output:\n",
        "\n",
        "French people are still waiting for their government to take action on climate change, a survey by polling agency Ifop found, as the country struggles with its worst floods and wildfires in decades.\n",
        "\n",
        "A total of 64 percent of respondents said they were concerned about the effects climate change could have on their lives, with just under half saying they felt it could have an impact on the country's economy.\n",
        "\n",
        "The poll also found that a quarter of French people said they believed climate change was a \"very important issue,\" compared to just 10 percent who said the same in the United Kingdom.\n",
        "\n",
        "French citizens are also concerned about the country's economy, with a third of respondents saying it would be \"very bad\" for the economy if the government did not take action on climate change.\n",
        "\n",
        "Ifop surveyed 2,500 people in France, the United Kingdom, Germany, and Italy in the run up to Christmas.\n",
        "\n",
        "The poll comes after a series of deadly floods in the country,\n",
        "\n",
        "TOTAL TIME ELAPSED: 46.62s"
      ],
      "metadata": {
        "id": "R3P2XQL6hzFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT-2 output:\n",
        "\n",
        "Turkish people are being forced to pay for a government-funded project to build a bridge over the Bosphorus Strait, a Turkish newspaper reported Tuesday.\n",
        "\n",
        "\n",
        "The bridge would be a key part of a plan to build a bridge over the strait that would cut off a major shipping route for Turkey from the European Union.\n",
        "\n",
        "\n",
        "The bridge, which is being financed with a 1.5 billion Turkish Liras ($9.5 million) loan from the Turkish government, is being built by the Turkish company Aselsan.\n",
        "\n",
        "\n",
        "But the project has been delayed, and it is unclear when construction will begin.\n",
        "\n",
        "\n",
        "The project has been delayed for years because of a dispute with the Turkish government, which is concerned about the cost and the environmental impact.\n",
        "\n",
        "\n",
        "Aselsan, a major construction and engineering company, is a member of the consortium that has built the bridge over the Bosphorus.\n",
        "\n",
        "\n",
        "The project was first announced in 2009 and the project was initially expected\n",
        "\n",
        "TOTAL TIME ELAPSED: 44.53s"
      ],
      "metadata": {
        "id": "b3fVvlyShYpk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous remarquons que GPT2-large est plus performant et les résultats obtenus semblent plus correcte que celui de gpt2-base, par contre, il peut partir très facilement en hors sujet."
      ],
      "metadata": {
        "id": "8b-5TmO_jHTs"
      }
    }
  ]
}
