{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Credits & Content\n",
        "**Author:** Bastien Hottelet\n",
        "\n",
        "**Date:** 10/03/2024\n",
        "\n",
        "**Content:**\n",
        "\n",
        "* Environment Setup\n",
        "* Definition of model related functions\n",
        "* Loading and configuration of the model\n",
        "* Dataset importation and Fine tuning\n",
        "  + SQuAD\n",
        "  + QuAC\n",
        "  + PubMedQA\n",
        "  + BioASQ - Task B\n",
        "  + MedQuAD \n",
        "* Saving the model to Google Drive\n",
        "* Loading the model from Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmit18uRGFzl"
      },
      "source": [
        "# Environment Setup\n",
        "\n",
        "Installation of all the required dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOJugUN1FuvC",
        "outputId": "3e149b77-d963-4354-bd50-31e655345fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-nlp\n",
            "  Downloading keras_nlp-0.8.2-py3-none-any.whl (465 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/465.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.5/465.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-core (from keras-nlp)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (23.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (2023.12.25)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (13.7.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.1.8)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.2.0)\n",
            "Collecting tensorflow-text (from keras-nlp)\n",
            "  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-nlp) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-nlp) (4.66.2)\n",
            "Collecting namex (from keras-core->keras-nlp)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-nlp) (3.9.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (2.16.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp) (0.16.1)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp) (2.15.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nlp) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.15.0)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.13.0->tensorflow-text->keras-nlp) (2.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-nlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-nlp) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-nlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-nlp) (2024.2.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.2.2)\n",
            "Installing collected packages: namex, keras-core, tensorflow-text, keras-nlp\n",
            "Successfully installed keras-core-0.1.7 keras-nlp-0.8.2 namex-0.0.7 tensorflow-text-2.15.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install keras-nlp\n",
        "%pip install pandas # To handle the datasets\n",
        "%pip install -q --upgrade keras  # Upgrade to Keras 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dra4yrZ9K-Mz",
        "outputId": "d1b7ced2-a8ee-45b7-d942-1013bbf2ea0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VtcYcMLGQtU"
      },
      "source": [
        "Importing all the required dependencies and enabling mixed precision to make the training faster.\n",
        "\n",
        "Set the Keras Backend to Tensorflow as asked in the requirements of the project (could have used \"jax\" or \"torch\" otherwise)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EPH_d3Y3GOAd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import time\n",
        "import keras\n",
        "import keras_nlp\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGdIsIrZGT_s"
      },
      "source": [
        "Definition of some useful hyperparameter that will make the code editing easier. (Only EPOCHS and BATCH_SIZE might be edited after depending the next training dataset's complexity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JidlyOZ3GVZU"
      },
      "outputs": [],
      "source": [
        "# General hyperparameters\n",
        "EPOCHS = 8\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "GPT2_PRESET = \"gpt2_large_en\"\n",
        "\n",
        "# LoRA-specific hyperparameters\n",
        "RANK = 4\n",
        "ALPHA = 32.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQe_LlfnGh3w"
      },
      "source": [
        "# Model Related Functions\n",
        "All functions related to the model and the operations done with it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xdT4a4AGjm5"
      },
      "source": [
        "Cleaning of the answer, removal of the original prompt engineering and cut at the end of the last finished sentence in the answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8-V6BwfBGkVO"
      },
      "outputs": [],
      "source": [
        "def clean_answer_text(text: str) -> str:\n",
        "    # Define the start marker for the model's response\n",
        "    response_start = text.find(\"[ANSWER]\") + len(\"[ANSWER]\")\n",
        "\n",
        "    # Extract everything after \"Doctor:\"\n",
        "    response_text = text[response_start:].strip()\n",
        "    last_dot_index = response_text.rfind(\".\")\n",
        "    if last_dot_index != -1:\n",
        "      response_text = response_text[:last_dot_index + 1]\n",
        "\n",
        "    # Additional cleaning if necessary (e.g., removing leading/trailing spaces or new lines)\n",
        "    response_text = response_text.strip()\n",
        "\n",
        "    return response_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aea0FrRhGn6M"
      },
      "source": [
        "Function to generate a text from a prompt using the model and the two functions defined previously to clean our answer.\n",
        "Also include some prompt engineering to improve the answer quality that we will get from our model. Attempt to turn the text generation nature of the model into a question answering model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wILrrKTRGnGS"
      },
      "outputs": [],
      "source": [
        "def generate_responses(model, question):\n",
        "    prompt = f\"[QUESTION] {question} [ANSWER]\"\n",
        "    output = model.generate(prompt, max_length=1024)\n",
        "    # Clean and extract the model's response from `output`\n",
        "    return clean_answer_text(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng_9d6Y1GqTU"
      },
      "source": [
        "Function creating the optimizer and loss objects needed in our LoRA model.\n",
        "\n",
        "Optimizer is AdamW and loss is SparseCategoricalCrossentropy, those are both the default choice for language modeling tasks, they tend to be effective and generally more efficient than others so we will stick to them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zjYB0cshGqvA"
      },
      "outputs": [],
      "source": [
        "def get_optimizer_and_loss():\n",
        "    optimizer = keras.optimizers.AdamW(\n",
        "        learning_rate=5e-5,\n",
        "        weight_decay=0.01,\n",
        "        epsilon=1e-6,\n",
        "        global_clipnorm=1.0,  # Gradient clipping.\n",
        "    )\n",
        "    # Exclude layernorm and bias terms from weight decay.\n",
        "    optimizer.exclude_from_weight_decay(var_names=[\"bias\"])\n",
        "    optimizer.exclude_from_weight_decay(var_names=[\"gamma\"])\n",
        "    optimizer.exclude_from_weight_decay(var_names=[\"beta\"])\n",
        "\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    return optimizer, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydiOOkoJGude"
      },
      "source": [
        "Function to list all the layers of a given model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_ucGeUA_GryX"
      },
      "outputs": [],
      "source": [
        "def list_all_layers(model, prefix=\"\", level=0):\n",
        "    for i, layer in enumerate(model.layers):\n",
        "        # Construct a new prefix for the current layer\n",
        "        layer_info = f\"{prefix}Layer {i}: {layer.name} (Type: {type(layer).__name__}, Trainable: {layer.trainable})\"\n",
        "        print(\"  \" * level + layer_info)\n",
        "\n",
        "        # Check for nested Keras models\n",
        "        if hasattr(layer, 'layers'):\n",
        "            list_all_layers(layer, prefix=prefix, level=level+1)\n",
        "\n",
        "        # Specific handling to reach deeper into TransformerDecoder or similar custom layers\n",
        "        if hasattr(layer, '_self_attention_layer'):\n",
        "            self_attention = layer._self_attention_layer\n",
        "            print_self_attention_details(self_attention, level=level+2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSF1lHpBGwIN"
      },
      "source": [
        "Function to list all the details about a self_attention layer, useful when checking our model after reverting our LoRA changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7gepQ4B9Gu9g"
      },
      "outputs": [],
      "source": [
        "def print_self_attention_details(self_attention_layer, level=0):\n",
        "    for attr in ['_query_dense', '_key_dense', '_value_dense', '_output_dense']:\n",
        "        if hasattr(self_attention_layer, attr):\n",
        "            layer = getattr(self_attention_layer, attr)\n",
        "            if layer:\n",
        "                print(\"  \" * level + f\"{attr}: (Type: {type(layer).__name__}, Trainable: {layer.trainable})\")\n",
        "                if hasattr(layer, 'layers'):  # In case your custom layer contains sublayers\n",
        "                    list_all_layers(layer, level=level+1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J1aK9w5GyaB"
      },
      "source": [
        "## LoRA (Low Rank Adaptation)\n",
        "In this notebook, we will use Keras LoRA implementation.\n",
        "LoRA is a training technique used for large language models (LLM) to train them more efficiently and with a less time consuming approach.\n",
        "How it works is the following:\n",
        "- Look at the pretrained model's weights\n",
        "- Determine the linearly independent and dependent columns of the matrix\n",
        "- Create the new LoRA layer with only the linearly independant matrix columns\n",
        "- Freeze the pretrained's model weights\n",
        "- Train the LoRA layer weights\n",
        "- Merge the weights of the pretrained model and the LoRA layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yli1WG2TG1jF"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bv71yESHHW2"
      },
      "source": [
        "Implementation of our LoRA layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VOXsCF62Gy1L"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class LoraLayer(keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        original_layer,\n",
        "        rank=8,\n",
        "        alpha=32,\n",
        "        trainable=False,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        # We want to keep the name of this layer the same as the original\n",
        "        # dense layer.\n",
        "        original_layer_config = original_layer.get_config()\n",
        "        name = original_layer_config[\"name\"]\n",
        "\n",
        "        kwargs.pop(\"name\", None)\n",
        "\n",
        "        super().__init__(name=name, trainable=trainable, **kwargs)\n",
        "\n",
        "        self.rank = rank\n",
        "        self.alpha = alpha\n",
        "\n",
        "        self._scale = alpha / rank\n",
        "\n",
        "        self._num_heads = original_layer_config[\"output_shape\"][-2]\n",
        "        self._hidden_dim = self._num_heads * original_layer_config[\"output_shape\"][-1]\n",
        "\n",
        "        # Layers.\n",
        "\n",
        "        # Original dense layer.\n",
        "        self.original_layer = original_layer\n",
        "        # No matter whether we are training the model or are in inference mode,\n",
        "        # this layer should be frozen.\n",
        "        self.original_layer.trainable = False\n",
        "\n",
        "        # LoRA dense layers.\n",
        "        self.A = keras.layers.Dense(\n",
        "            units=rank,\n",
        "            use_bias=False,\n",
        "            # Note: the original paper mentions that normal distribution was\n",
        "            # used for initialization. However, the official LoRA implementation\n",
        "            # uses \"Kaiming/He Initialization\".\n",
        "            kernel_initializer=keras.initializers.VarianceScaling(\n",
        "                scale=math.sqrt(5), mode=\"fan_in\", distribution=\"uniform\"\n",
        "            ),\n",
        "            trainable=trainable,\n",
        "            name=f\"lora_A\",\n",
        "        )\n",
        "        # B has the same `equation` and `output_shape` as the original layer.\n",
        "        # `equation = abc,cde->abde`, where `a`: batch size, `b`: sequence\n",
        "        # length, `c`: `hidden_dim`, `d`: `num_heads`,\n",
        "        # `e`: `hidden_dim//num_heads`. The only difference is that in layer `B`,\n",
        "        # `c` represents `rank`.\n",
        "        self.B = keras.layers.EinsumDense(\n",
        "            equation=original_layer_config[\"equation\"],\n",
        "            output_shape=original_layer_config[\"output_shape\"],\n",
        "            kernel_initializer=\"zeros\",\n",
        "            trainable=trainable,\n",
        "            name=f\"lora_B\",\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        original_output = self.original_layer(inputs)\n",
        "        if self.trainable:\n",
        "            # If we are fine-tuning the model, we will add LoRA layers' output\n",
        "            # to the original layer's output.\n",
        "            lora_output = self.B(self.A(inputs)) * self._scale\n",
        "            return original_output + lora_output\n",
        "\n",
        "        # If we are in inference mode, we \"merge\" the LoRA layers' weights into\n",
        "        # the original layer's weights - more on this in the text generation\n",
        "        # section!\n",
        "        return original_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-0syzqIHJvG"
      },
      "source": [
        "# Load and configure the Model\n",
        "Load the original/basic model and preprocessor for GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC5TLTtQHJKS",
        "outputId": "801ab104-092a-4742-96f5-98005ebc23e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_large_en/2/download/tokenizer.json...\n",
            "100%|██████████| 448/448 [00:00<00:00, 493kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_large_en/2/download/assets/tokenizer/merges.txt...\n",
            "100%|██████████| 446k/446k [00:00<00:00, 1.40MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_large_en/2/download/assets/tokenizer/vocabulary.json...\n",
            "100%|██████████| 0.99M/0.99M [00:00<00:00, 2.66MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_large_en/2/download/config.json...\n",
            "100%|██████████| 485/485 [00:00<00:00, 833kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_large_en/2/download/model.weights.h5...\n",
            "100%|██████████| 2.88G/2.88G [00:56<00:00, 54.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Load the original model.\n",
        "preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
        "    GPT2_PRESET,\n",
        "    sequence_length=128,\n",
        ")\n",
        "lora_model = keras_nlp.models.GPT2CausalLM.from_preset(\n",
        "    GPT2_PRESET,\n",
        "    preprocessor=preprocessor,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY2GxtjiHOEB"
      },
      "source": [
        "Check the original model architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iDi1IT6HOZ1",
        "outputId": "16b672d9-6da2-4001-98be-d5abf3f557a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer 0: padding_mask (Type: InputLayer, Trainable: True)\n",
            "Layer 1: token_ids (Type: InputLayer, Trainable: True)\n",
            "Layer 2: gpt2_backbone (Type: GPT2Backbone, Trainable: True)\n",
            "  Layer 0: token_ids (Type: InputLayer, Trainable: True)\n",
            "  Layer 1: token_embedding (Type: ReversibleEmbedding, Trainable: True)\n",
            "  Layer 2: position_embedding (Type: PositionEmbedding, Trainable: True)\n",
            "  Layer 3: embeddings_add (Type: Add, Trainable: True)\n",
            "  Layer 4: embeddings_dropout (Type: Dropout, Trainable: True)\n",
            "  Layer 5: padding_mask (Type: InputLayer, Trainable: True)\n",
            "  Layer 6: transformer_layer_0 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 7: transformer_layer_1 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 8: transformer_layer_2 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 9: transformer_layer_3 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 10: transformer_layer_4 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 11: transformer_layer_5 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 12: transformer_layer_6 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 13: transformer_layer_7 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 14: transformer_layer_8 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 15: transformer_layer_9 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 16: transformer_layer_10 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 17: transformer_layer_11 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 18: transformer_layer_12 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 19: transformer_layer_13 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 20: transformer_layer_14 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 21: transformer_layer_15 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 22: transformer_layer_16 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 23: transformer_layer_17 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 24: transformer_layer_18 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 25: transformer_layer_19 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 26: transformer_layer_20 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 27: transformer_layer_21 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 28: transformer_layer_22 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 29: transformer_layer_23 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 30: transformer_layer_24 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 31: transformer_layer_25 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 32: transformer_layer_26 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 33: transformer_layer_27 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 34: transformer_layer_28 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 35: transformer_layer_29 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 36: transformer_layer_30 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 37: transformer_layer_31 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 38: transformer_layer_32 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 39: transformer_layer_33 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 40: transformer_layer_34 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 41: transformer_layer_35 (Type: TransformerDecoder, Trainable: True)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: True)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: True)\n",
            "  Layer 42: layer_norm (Type: LayerNormalization, Trainable: True)\n",
            "Layer 3: token_embedding (Type: ReversibleEmbedding, Trainable: True)\n"
          ]
        }
      ],
      "source": [
        "list_all_layers(lora_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "potS3i6gHSib"
      },
      "source": [
        "Override the original query/value projection matrices with the new LoRA layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KnjNEOBxHTlf"
      },
      "outputs": [],
      "source": [
        "for layer_idx in range(lora_model.backbone.num_layers):\n",
        "    # Change query dense layer.\n",
        "    decoder_layer = lora_model.backbone.get_layer(f\"transformer_layer_{layer_idx}\")\n",
        "    self_attention_layer = decoder_layer._self_attention_layer\n",
        "    # Allow mutation to Keras layer state.\n",
        "    self_attention_layer._tracker.locked = False\n",
        "\n",
        "    # Change query dense layer.\n",
        "    self_attention_layer._query_dense = LoraLayer(\n",
        "        self_attention_layer._query_dense,\n",
        "        rank=RANK,\n",
        "        alpha=ALPHA,\n",
        "        trainable=True,\n",
        "    )\n",
        "\n",
        "    # Change value dense layer.\n",
        "    self_attention_layer._value_dense = LoraLayer(\n",
        "        self_attention_layer._value_dense,\n",
        "        rank=RANK,\n",
        "        alpha=ALPHA,\n",
        "        trainable=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHz6QctzHVKb"
      },
      "source": [
        "Make sure the chain of computation is still correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OBvmXFXvHW1Y"
      },
      "outputs": [],
      "source": [
        "lora_model(preprocessor([\"LoRA is very useful for quick LLM finetuning\"])[0])\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbbjbiBdHbnY"
      },
      "source": [
        "Freeze the pretrained model so only the LoRA layers will be trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "x2jhZy4RHbdp"
      },
      "outputs": [],
      "source": [
        "for layer in lora_model._flatten_layers():\n",
        "    lst_of_sublayers = list(layer._flatten_layers())\n",
        "\n",
        "    if len(lst_of_sublayers) == 1:  # \"leaves of the model\"\n",
        "        if layer.name in [\"lora_A\", \"lora_B\"]:\n",
        "            layer.trainable = True\n",
        "        else:\n",
        "            layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "gDvcV8pbHgx8",
        "outputId": "32a210fe-22e9-4b6d-c25a-ce04e36fe8b1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gpt2_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mPreprocessor: \"gpt2_causal_lm_preprocessor\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gpt2_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GPT2Tokenizer</span>)                     │                                              <span style=\"color: #00af00; text-decoration-color: #00af00\">50,257</span> │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gpt2_tokenizer (\u001b[38;5;33mGPT2Tokenizer\u001b[0m)                     │                                              \u001b[38;5;34m50,257\u001b[0m │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt2_causal_lm\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"gpt2_causal_lm\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gpt2_backbone (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GPT2Backbone</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">774,767,360</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">64,328,960</span> │ gpt2_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gpt2_backbone (\u001b[38;5;33mGPT2Backbone\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)        │     \u001b[38;5;34m774,767,360\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50257\u001b[0m)       │      \u001b[38;5;34m64,328,960\u001b[0m │ gpt2_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">774,767,360</span> (2.89 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m774,767,360\u001b[0m (2.89 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">737,280</span> (2.81 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m737,280\u001b[0m (2.81 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">774,030,080</span> (2.88 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m774,030,080\u001b[0m (2.88 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "lora_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aGKKXjKKDcN"
      },
      "source": [
        "# Fine Tuning of the Model\n",
        "\n",
        "In this training sequence, we aim to develop a model capable of understanding and generating answers for healthcare-related questions. The logic behind the chosen sequence is to gradually transition the model from general language understanding to specialized healthcare knowledge.\n",
        "\n",
        "The datasets we will use are:\n",
        "- SQuAD\n",
        "- QuAC\n",
        "- BioASQ (Task A & B)\n",
        "- MedQuAD\n",
        "- PubMedQA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB2OlcSmKkRX"
      },
      "source": [
        "In this code we define the file path that will be used for each dataset throughout the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XMVX55YhKoSQ"
      },
      "outputs": [],
      "source": [
        "SQUAD_FILEPATH = \"/content/drive/MyDrive/Medical_Chatbot_GPT2/Datasets/SQuAD/data.json\"\n",
        "QUAC_FILEPATH = \"/content/drive/MyDrive/Medical_Chatbot_GPT2/Datasets/QuAC/data.json\"\n",
        "PUBMEDQA_FILEPATH = \"/content/drive/MyDrive/Medical_Chatbot_GPT2/Datasets/PubMedQA/data.json\"\n",
        "BIOASQ_B_FILEPATH = \"/content/drive/MyDrive/Medical_Chatbot_GPT2/Datasets/BioASQ-training12b/data.json\"\n",
        "MEDQUAD_FILEPATH = \"/content/drive/MyDrive/Medical_Chatbot_GPT2/Datasets/MedQuAD/data.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNo53S54QM2O"
      },
      "source": [
        "Get optimizer and loss functions from the previously written function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8iVFrR9tQKMF"
      },
      "outputs": [],
      "source": [
        "optimizer, loss = get_optimizer_and_loss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzd1fUvVQQIT"
      },
      "source": [
        "Perplexity is one of the most common metrics for evaluating language models during training. It measures how well a probability distribution or probability model predicts a sample. A lower perplexity score indicates that the model is better at predicting the sample.\n",
        "\n",
        "That's why we will create our own implementation of perplexity in this notebook and then compile our model with this custom metric and the optimizer and loss function retrieved earlier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZIo8iT5VQiHj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def perplexity_metric(y_true, y_pred):\n",
        "    cross_entropy = K.sparse_categorical_crossentropy(y_true, y_pred)\n",
        "    perplexity = K.exp(cross_entropy)\n",
        "    return K.mean(perplexity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LPU8ClHoQKjO"
      },
      "outputs": [],
      "source": [
        "lora_model.compile(optimizer=optimizer,\n",
        "                   loss=loss,\n",
        "                   metrics=[perplexity_metric])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKvuPV1cHfbd"
      },
      "source": [
        "## 1 - Starting with SQuAD\n",
        "\n",
        "Provides a solid foundation in general language comprehension and answer generation across a wide range of topics, essential for the initial stages of model training.\n",
        "\n",
        "Link to the dataset: https://rajpurkar.github.io/SQuAD-explorer/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QUCTZteZPuyo"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load the SQuAD dataset\n",
        "with open(SQUAD_FILEPATH) as f:\n",
        "    squad_data = json.load(f)\n",
        "\n",
        "# Prepare lists for inputs and targets\n",
        "squad_formatted_data = []\n",
        "\n",
        "for article in squad_data['data']:\n",
        "    for paragraph in article['paragraphs']:\n",
        "        context = paragraph['context']\n",
        "        for qa in paragraph['qas']:\n",
        "            question = qa['question']\n",
        "            # Assuming the first answer is used for simplicity, and checking if answers are available\n",
        "            answer = qa['answers'][0]['text'] if qa['answers'] else 'No Answer Found'\n",
        "\n",
        "            # Format the input text by concatenating question and context\n",
        "            input_text = f\"[QUESTION] {question} [CONTEXT] {context} [ANSWER] {answer}\"\n",
        "\n",
        "            squad_formatted_data.append(input_text)\n",
        "\n",
        "del squad_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TEioVY8VLUv",
        "outputId": "9e1f84c9-8ce2-44ad-ed29-9d8005b3749a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "130319"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(squad_formatted_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "JbMdGsom9z1A"
      },
      "outputs": [],
      "source": [
        "# Make sure we have the correct parameters according to the dataset's complexity\n",
        "EPOCHS = 2\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vybCruG2P_8K",
        "outputId": "c8e845b1-90c0-462c-82ff-93a566a7481c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m16290/16290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2716s\u001b[0m 147ms/step - loss: 2.5936 - perplexity_metric: 158391120.0000\n",
            "Epoch 2/2\n",
            "\u001b[1m16290/16290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2116s\u001b[0m 130ms/step - loss: 2.5318 - perplexity_metric: 149693488.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b41e839c910>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "lora_model.fit(squad_formatted_data,\n",
        "               epochs=EPOCHS,\n",
        "               batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-YaPpmgR8kh"
      },
      "source": [
        "## 2 - Proceed with QuAC\n",
        "\n",
        "This dataset will introduce our model to the context of dialogue-based question answering. It's a good step after SQuAD because it builds on the model's understanding of Q&A by adding the complexity of context and back-and-forth interaction, which is closer to real-life conversations and can be beneficial for understanding patient queries.\n",
        "\n",
        "Link to the dataset: https://quac.ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_KOFJ3Y3Stjl"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load the QuAC dataset\n",
        "with open(QUAC_FILEPATH) as f:\n",
        "    quac_data = json.load(f)\n",
        "\n",
        "# Prepare a list for the concatenated input texts\n",
        "quac_formatted_data = []\n",
        "\n",
        "for data_item in quac_data['data']:\n",
        "    for paragraph in data_item['paragraphs']:\n",
        "        context = paragraph['context']\n",
        "        for qa in paragraph['qas']:\n",
        "            question = qa['question']\n",
        "            # Checking if answers are available and choosing the first answer\n",
        "            # QuAC has instances marked as 'CANNOTANSWER', handle accordingly\n",
        "            if qa['answers']:\n",
        "                answer = qa['answers'][0]['text']\n",
        "            else:\n",
        "                # Handle 'CANNOTANSWER' or no answer available scenarios\n",
        "                answer = 'CANNOTANSWER'\n",
        "\n",
        "            # Format the input text by concatenating question, context, and answer\n",
        "            input_text = f\"[QUESTION] {question} [CONTEXT] {context} [ANSWER] {answer}\"\n",
        "\n",
        "            quac_formatted_data.append(input_text)\n",
        "\n",
        "del quac_data  # Optional: free up memory if the dataset is no longer needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uU2UjY-99JF",
        "outputId": "3367f5cc-e26b-4cfa-a196-ea2ab447ddc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "83568"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(quac_formatted_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3ojiCQ-O98sX"
      },
      "outputs": [],
      "source": [
        "# Make sure we have the correct parameters according to the dataset's complexity\n",
        "EPOCHS = 2\n",
        "BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCwKsVg1Ucfj",
        "outputId": "5394a4f9-7d5c-47d6-d876-9537d97a6ac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m10446/10446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1353s\u001b[0m 129ms/step - loss: 2.8029 - perplexity_metric: 169088112.0000\n",
            "Epoch 2/2\n",
            "\u001b[1m10446/10446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1364s\u001b[0m 131ms/step - loss: 2.7289 - perplexity_metric: 154497936.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b4069a3b100>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "lora_model.fit(quac_formatted_data,\n",
        "               epochs=EPOCHS,\n",
        "               batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckqrsQ98Scj4"
      },
      "source": [
        "## 3 - Learn about healthcare with PubMedQA\n",
        "\n",
        "As this dataset is designed for QA tasks, it will integrate well with previous trainings and it will set the basic knowledge for the healthcare field with it's various study-driven answers.\n",
        "\n",
        "As the answer mainly talk about studies, we won't do too many epochs to avoid our model going in that direction because we still want the answer to feel natural.\n",
        "\n",
        "Link to the dataset: https://pubmedqa.github.io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-cDFLHlT-FWg"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load the PubMedQA dataset\n",
        "with open(PUBMEDQA_FILEPATH) as f:\n",
        "    pubmedqa_data = json.load(f)\n",
        "\n",
        "# Prepare a list for the concatenated input texts\n",
        "pubmedqa_formatted_data = []\n",
        "\n",
        "for pubmed_id, item in pubmedqa_data.items():\n",
        "    question = item[\"QUESTION\"]\n",
        "    # Join all contexts into a single string; adjust based on your model's capacity\n",
        "    context = \" \".join(item[\"CONTEXTS\"])\n",
        "    answer = item[\"LONG_ANSWER\"]\n",
        "\n",
        "    # Format the input text by concatenating question and context, and formatting the answer\n",
        "    input_text = f\"[QUESTION] {question} [CONTEXT] {context} [ANSWER] {answer}\"\n",
        "\n",
        "    pubmedqa_formatted_data.append(input_text)\n",
        "\n",
        "# Optional: Free up memory if the raw dataset is no longer needed\n",
        "del pubmedqa_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wauDNzBX_AO_",
        "outputId": "6dc75fb3-bdfc-4178-f072-1c96b6a130f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(pubmedqa_formatted_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "NoNKspnZ-FgD"
      },
      "outputs": [],
      "source": [
        "# Make sure we have the correct parameters according to the dataset's complexity\n",
        "EPOCHS = 2\n",
        "BATCH_SIZE = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH7O1vYJ-Fp9",
        "outputId": "3433c7a7-8280-4971-a8ff-08f180cfc4ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 78ms/step - loss: 2.7014 - perplexity_metric: 186258256.0000\n",
            "Epoch 2/2\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 2.5396 - perplexity_metric: 126036064.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b41e8369450>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "lora_model.fit(pubmedqa_formatted_data,\n",
        "               epochs=EPOCHS,\n",
        "               batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avIZHPaUSInj"
      },
      "source": [
        "## 4 - Introduce BioASQ\n",
        "\n",
        "  This dataset is particularly challenging due to its focus on biomedical semantic indexing and question answering. It's a significant step towards specializing our model towards the healthcare field, leveraging the foundational knowledge from previous steps and applying it to biomedical research questions.\n",
        "\n",
        "  Link to the dataset: http://participants-area.bioasq.org/datasets/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Jf5s4dAE-yVW"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load the BioASQ Task B dataset\n",
        "with open(BIOASQ_B_FILEPATH, 'r') as f:\n",
        "    bioasq_data = json.load(f)\n",
        "\n",
        "# Prepare a list for the concatenated input texts\n",
        "bioasq_formatted_data = []\n",
        "\n",
        "for question_item in bioasq_data['questions']:\n",
        "    question = question_item['body']\n",
        "    # Check if 'ideal_answer' exists and handle accordingly\n",
        "    if 'ideal_answer' in question_item and question_item['ideal_answer']:\n",
        "        # 'ideal_answer' might be a list or a string depending on the dataset version; handle both cases\n",
        "        ideal_answer = question_item['ideal_answer'] if isinstance(question_item['ideal_answer'], str) else ' '.join(question_item['ideal_answer'])\n",
        "    else:\n",
        "        ideal_answer = 'No Ideal Answer Found'\n",
        "\n",
        "    # Format the input text by concatenating question and the ideal answer\n",
        "    input_text = f\"[QUESTION] {question} [ANSWER] {ideal_answer}\"\n",
        "\n",
        "    bioasq_formatted_data.append(input_text)\n",
        "\n",
        "del bioasq_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k73H6TRW-qJS",
        "outputId": "32eca127-0722-457b-e0c2-966dbdc58657"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5049"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(bioasq_formatted_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "b5R6wdDM-6RT"
      },
      "outputs": [],
      "source": [
        "# Make sure we have the correct parameters according to the dataset's complexity\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h8NpM2R-sB9",
        "outputId": "c132e0a5-0ec7-42bd-85b5-5fe3ab974e17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 522ms/step - loss: 1.6098 - perplexity_metric: 132443264.0000\n",
            "Epoch 2/5\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 131ms/step - loss: 1.5531 - perplexity_metric: 114022784.0000\n",
            "Epoch 3/5\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 131ms/step - loss: 1.5382 - perplexity_metric: 108459712.0000\n",
            "Epoch 4/5\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 130ms/step - loss: 1.5265 - perplexity_metric: 107680880.0000\n",
            "Epoch 5/5\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 130ms/step - loss: 1.5180 - perplexity_metric: 104533872.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b4065b4a440>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "lora_model.fit(bioasq_formatted_data,\n",
        "               epochs=EPOCHS,\n",
        "               batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-3S56ijSQ06"
      },
      "source": [
        " ## 5 - Fine-tune with MedQuAD\n",
        "\n",
        "  Although named similarly to SQuAD, MedQuAD is focused on medical information. It will help us guide our model in the direction of naturally answering questions and also expand the model's knowledge and reinforce our commitment to QA text generation.\n",
        "\n",
        "  Link to the dataset: https://www.kaggle.com/datasets/jpmiller/layoutlm\n",
        "\n",
        "  (This is the required dataset from the project)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "NMCxIvDs-OAm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the MedQuAD dataset\n",
        "medquad_df = pd.read_csv(MEDQUAD_FILEPATH)\n",
        "\n",
        "# Prepare a list for the concatenated input texts\n",
        "medquad_formatted_data = []\n",
        "\n",
        "for index, row in medquad_df.iterrows():\n",
        "    question = row['question']\n",
        "    answer = row['answer']\n",
        "\n",
        "    # Format the input text by concatenating question and answer\n",
        "    input_text = f\"[QUESTION] {question} [ANSWER] {answer}\"\n",
        "\n",
        "    medquad_formatted_data.append(input_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h4sVepg-1ws",
        "outputId": "805a543a-4de5-4c65-847d-f450cfa28000"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16412"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(medquad_formatted_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "pQRNQoBE-0lJ"
      },
      "outputs": [],
      "source": [
        "# Make sure we have the correct parameters according to the dataset's complexity\n",
        "EPOCHS = 6\n",
        "BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucWYpNwJ-zpE",
        "outputId": "3e45b400-8a8f-46fc-f5bf-514858900245"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m2052/2052\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 130ms/step - loss: 1.5813 - perplexity_metric: 49007960.0000\n",
            "Epoch 2/6\n",
            "\u001b[1m2052/2052\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 137ms/step - loss: 1.4502 - perplexity_metric: 36960148.0000\n",
            "Epoch 3/6\n",
            "\u001b[1m2052/2052\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 131ms/step - loss: 1.4114 - perplexity_metric: 34844496.0000\n",
            "Epoch 4/6\n",
            "\u001b[1m2052/2052\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 146ms/step - loss: 1.3856 - perplexity_metric: 33104676.0000\n",
            "Epoch 5/6\n",
            "\u001b[1m2052/2052\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 131ms/step - loss: 1.3662 - perplexity_metric: 33542386.0000\n",
            "Epoch 6/6\n",
            "\u001b[1m2052/2052\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 130ms/step - loss: 1.3511 - perplexity_metric: 35898204.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b406a921810>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "lora_model.fit(medquad_formatted_data,\n",
        "               epochs=EPOCHS,\n",
        "               batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3blstwubjBQ"
      },
      "source": [
        "# Saving our Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5lagkiSiMEp"
      },
      "source": [
        "Remove the LoRA layers from the model and merge the weights to then save our model for inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "mQYPGtU7x51e"
      },
      "outputs": [],
      "source": [
        "for layer_idx in range(lora_model.backbone.num_layers):\n",
        "    self_attention_layer = lora_model.backbone.get_layer(\n",
        "        f\"transformer_layer_{layer_idx}\"\n",
        "    )._self_attention_layer\n",
        "\n",
        "    # Merge query dense layer.\n",
        "    query_lora_layer = self_attention_layer._query_dense\n",
        "\n",
        "    A_weights = query_lora_layer.A.kernel  # (768, 1) (a, b)\n",
        "    B_weights = query_lora_layer.B.kernel  # (1, 12, 64) (b, c, d)\n",
        "    increment_weights = tf.einsum(\"ab,bcd->acd\", A_weights, B_weights) * (ALPHA / RANK)\n",
        "    query_lora_layer.original_layer.kernel.assign_add(increment_weights)\n",
        "\n",
        "    # PART MISSING IN KERAS DOCUMENTATION / ESSENTIAL FOR SAVING\n",
        "    self_attention_layer._query_dense = query_lora_layer.original_layer\n",
        "\n",
        "    # Merge value dense layer.\n",
        "    value_lora_layer = self_attention_layer._value_dense\n",
        "\n",
        "    A_weights = value_lora_layer.A.kernel  # (768, 1) (a, b)\n",
        "    B_weights = value_lora_layer.B.kernel  # (1, 12, 64) (b, c, d)\n",
        "    increment_weights = tf.einsum(\"ab,bcd->acd\", A_weights, B_weights) * (ALPHA / RANK)\n",
        "    value_lora_layer.original_layer.kernel.assign_add(increment_weights)\n",
        "\n",
        "    # PART MISSING IN KERAS DOCUMENTATION / ESSENTIAL FOR SAVING\n",
        "    self_attention_layer._value_dense = value_lora_layer.original_layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOT5z-HG6eUp",
        "outputId": "f13f951b-44ad-49e2-deaa-21bed2025026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diabetes is a disease in which you have a low- or high-calorie diet. Diabetics eat too much sugar and not enough protein. The high calorie intake causes blood glucose levels to rise.\n",
            "                \n",
            "High blood glucose levels cause damage to cells and organs. These damages are caused by the body's immune system attacking the pancreas, liver, and other cells.\n"
          ]
        }
      ],
      "source": [
        "print(generate_responses(lora_model, \"What is diabete?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnhxLvQ-Adjo"
      },
      "source": [
        "Set trainable to false to save our model for inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "ZE1MCjSax7Xg"
      },
      "outputs": [],
      "source": [
        "lora_model.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vAX1hPCiQXZ"
      },
      "source": [
        "Verify that we did remove every LoRA layer from the LoRA model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_T0GDTlx808",
        "outputId": "f78833ce-5c77-4390-82d7-b2557241fda9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer 0: padding_mask (Type: InputLayer, Trainable: False)\n",
            "Layer 1: token_ids (Type: InputLayer, Trainable: False)\n",
            "Layer 2: gpt2_backbone (Type: GPT2Backbone, Trainable: False)\n",
            "  Layer 0: token_ids (Type: InputLayer, Trainable: False)\n",
            "  Layer 1: token_embedding (Type: ReversibleEmbedding, Trainable: False)\n",
            "  Layer 2: position_embedding (Type: PositionEmbedding, Trainable: False)\n",
            "  Layer 3: embeddings_add (Type: Add, Trainable: False)\n",
            "  Layer 4: embeddings_dropout (Type: Dropout, Trainable: False)\n",
            "  Layer 5: padding_mask (Type: InputLayer, Trainable: False)\n",
            "  Layer 6: transformer_layer_0 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 7: transformer_layer_1 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 8: transformer_layer_2 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 9: transformer_layer_3 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 10: transformer_layer_4 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 11: transformer_layer_5 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 12: transformer_layer_6 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 13: transformer_layer_7 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 14: transformer_layer_8 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 15: transformer_layer_9 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 16: transformer_layer_10 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 17: transformer_layer_11 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 18: transformer_layer_12 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 19: transformer_layer_13 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 20: transformer_layer_14 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 21: transformer_layer_15 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 22: transformer_layer_16 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 23: transformer_layer_17 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 24: transformer_layer_18 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 25: transformer_layer_19 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 26: transformer_layer_20 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 27: transformer_layer_21 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 28: transformer_layer_22 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 29: transformer_layer_23 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 30: transformer_layer_24 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 31: transformer_layer_25 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 32: transformer_layer_26 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 33: transformer_layer_27 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 34: transformer_layer_28 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 35: transformer_layer_29 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 36: transformer_layer_30 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 37: transformer_layer_31 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 38: transformer_layer_32 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 39: transformer_layer_33 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 40: transformer_layer_34 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 41: transformer_layer_35 (Type: TransformerDecoder, Trainable: False)\n",
            "      _query_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _key_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _value_dense: (Type: EinsumDense, Trainable: False)\n",
            "      _output_dense: (Type: EinsumDense, Trainable: False)\n",
            "  Layer 42: layer_norm (Type: LayerNormalization, Trainable: False)\n",
            "Layer 3: token_embedding (Type: ReversibleEmbedding, Trainable: False)\n"
          ]
        }
      ],
      "source": [
        "list_all_layers(lora_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vco6GbBKiSh_"
      },
      "source": [
        "Compile the model without an optimizer to make sure we save it with the minimum of information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "x2bB8pKiblQT"
      },
      "outputs": [],
      "source": [
        "lora_model.compile(optimizer=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjAgyo6Lidok"
      },
      "source": [
        "Actually save the model in our Google Drive location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "J6O1gvGrboOt"
      },
      "outputs": [],
      "source": [
        "lora_model.save(\"/content/drive/MyDrive/Medical_Chatbot_GPT2/Model_Versions/LoRA_Model_CP3.keras\", include_optimizer=False) # Feel free to edit the Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xZM7Xukijc6"
      },
      "source": [
        "# Load our model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18_W_zgEijQn",
        "outputId": "b723ebb9-5996-4af9-ea3b-d38d3d24fc95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py:727: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'loss_scale_optimizer', because it has 4 variables whereas the saved optimizer has 0 variables. \n",
            "  trackable.load_own_variables(weights_store.get(inner_path))\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 0 variables. \n",
            "  trackable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "lora_model = keras.models.load_model(\"/content/drive/MyDrive/Medical_Chatbot_GPT2/Model_Versions/LoRA_Model_CP3.keras\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
